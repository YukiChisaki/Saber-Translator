"""
Manga Insight å­˜å‚¨æ¨¡å—

ç®¡ç†åˆ†æç»“æœçš„å­˜å‚¨å’Œè¯»å–ã€‚
"""

import os
import json
import logging
from typing import Dict, List, Optional, Any
from datetime import datetime

from src.shared.path_helpers import resource_path

logger = logging.getLogger("MangaInsight.Storage")

STORAGE_BASE_DIR = "data/manga_insight"


class AnalysisStorage:
    """åˆ†æç»“æœå­˜å‚¨ç®¡ç†å™¨"""
    
    def __init__(self, book_id: str):
        self.book_id = book_id
        self.base_path = resource_path(os.path.join(STORAGE_BASE_DIR, book_id))
        self._ensure_directories()
    
    def _ensure_directories(self):
        """ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨"""
        dirs = [
            self.base_path,
            os.path.join(self.base_path, "pages"),
            os.path.join(self.base_path, "chapters"),
            os.path.join(self.base_path, "batches"),
            os.path.join(self.base_path, "segments"),
            os.path.join(self.base_path, "embeddings")
        ]
        for dir_path in dirs:
            os.makedirs(dir_path, exist_ok=True)
    
    def _load_json(self, filename: str, default: Any = None) -> Any:
        """åŠ è½½ JSON æ–‡ä»¶"""
        filepath = os.path.join(self.base_path, filename)
        try:
            if os.path.exists(filepath):
                with open(filepath, 'r', encoding='utf-8') as f:
                    return json.load(f)
            return default if default is not None else {}
        except Exception as e:
            logger.error(f"åŠ è½½ JSON å¤±è´¥: {filepath} - {e}")
            return default if default is not None else {}
    
    def _save_json(self, filename: str, data: Any) -> bool:
        """ä¿å­˜ JSON æ–‡ä»¶"""
        filepath = os.path.join(self.base_path, filename)
        try:
            os.makedirs(os.path.dirname(filepath), exist_ok=True)
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            return True
        except Exception as e:
            logger.error(f"ä¿å­˜ JSON å¤±è´¥: {filepath} - {e}")
            return False
    
    async def load_metadata(self) -> Dict:
        return self._load_json("metadata.json")
    
    async def save_metadata(self, metadata: Dict) -> bool:
        metadata["updated_at"] = datetime.now().isoformat()
        return self._save_json("metadata.json", metadata)
    
    async def load_analysis_status(self) -> Dict:
        return self._load_json("analysis_status.json")
    
    async def save_analysis_status(self, status: Dict) -> bool:
        status["updated_at"] = datetime.now().isoformat()
        return self._save_json("analysis_status.json", status)
    
    async def load_content_snapshot(self) -> Optional[Dict]:
        return self._load_json("content_snapshot.json", None)
    
    async def save_content_snapshot(self, snapshot: Dict) -> bool:
        snapshot["created_at"] = datetime.now().isoformat()
        return self._save_json("content_snapshot.json", snapshot)
    
    async def load_page_analysis(self, page_num: int) -> Optional[Dict]:
        filename = f"pages/page_{page_num:03d}.json"
        return self._load_json(filename, None)
    
    async def save_page_analysis(self, page_num: int, analysis: Dict) -> bool:
        filename = f"pages/page_{page_num:03d}.json"
        analysis["saved_at"] = datetime.now().isoformat()
        return self._save_json(filename, analysis)
    
    async def load_chapter_analysis(self, chapter_id: str) -> Optional[Dict]:
        filename = f"chapters/{chapter_id}.json"
        return self._load_json(filename, None)
    
    async def save_chapter_analysis(self, chapter_id: str, analysis: Dict) -> bool:
        filename = f"chapters/{chapter_id}.json"
        analysis["saved_at"] = datetime.now().isoformat()
        return self._save_json(filename, analysis)
    
    async def load_timeline(self) -> Optional[Dict]:
        """åŠ è½½æ—¶é—´çº¿ç¼“å­˜"""
        return self._load_json("timeline.json", None)
    
    async def save_timeline(self, timeline_data: Dict) -> bool:
        """ä¿å­˜æ—¶é—´çº¿ç¼“å­˜"""
        timeline_data["saved_at"] = datetime.now().isoformat()
        return self._save_json("timeline.json", timeline_data)
    
    async def load_notes(self) -> Optional[List]:
        """åŠ è½½ç¬”è®°åˆ—è¡¨"""
        return self._load_json("notes.json", [])
    
    async def save_notes(self, notes: List) -> bool:
        """ä¿å­˜ç¬”è®°åˆ—è¡¨"""
        return self._save_json("notes.json", notes)
    
    async def has_timeline_cache(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ—¶é—´çº¿ç¼“å­˜"""
        filepath = os.path.join(self.base_path, "timeline.json")
        return os.path.exists(filepath)
    
    async def delete_timeline_cache(self) -> bool:
        """åˆ é™¤æ—¶é—´çº¿ç¼“å­˜"""
        filepath = os.path.join(self.base_path, "timeline.json")
        try:
            if os.path.exists(filepath):
                os.remove(filepath)
            return True
        except Exception as e:
            logger.error(f"åˆ é™¤æ—¶é—´çº¿ç¼“å­˜å¤±è´¥: {e}")
            return False
    
    async def load_overview(self) -> Dict:
        return self._load_json("overview.json")
    
    async def save_overview(self, overview: Dict) -> bool:
        overview["updated_at"] = datetime.now().isoformat()
        return self._save_json("overview.json", overview)
    
    # ============================================================
    # å‹ç¼©æ‘˜è¦å­˜å‚¨æ–¹æ³•ï¼ˆä¾›é—®ç­”å…¨å±€æ¨¡å¼ä½¿ç”¨ï¼‰
    # ============================================================
    
    async def load_compressed_context(self) -> Optional[Dict]:
        """
        åŠ è½½å‹ç¼©åçš„å…¨æ–‡æ‘˜è¦
        
        Returns:
            Dict: {
                "context": str,      # å‹ç¼©åçš„å…¨æ–‡æ‘˜è¦
                "source": str,       # æ•°æ®æ¥æº
                "group_count": int,  # åˆ†ç»„æ•°é‡
                "char_count": int,   # å­—ç¬¦æ•°
                "generated_at": str  # ç”Ÿæˆæ—¶é—´
            }
        """
        return self._load_json("compressed_context.json", None)
    
    async def save_compressed_context(self, data: Dict) -> bool:
        """ä¿å­˜å‹ç¼©åçš„å…¨æ–‡æ‘˜è¦"""
        data["saved_at"] = datetime.now().isoformat()
        return self._save_json("compressed_context.json", data)
    
    async def has_compressed_context(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å­˜åœ¨å‹ç¼©æ‘˜è¦"""
        filepath = os.path.join(self.base_path, "compressed_context.json")
        return os.path.exists(filepath)
    
    async def delete_compressed_context(self) -> bool:
        """åˆ é™¤å‹ç¼©æ‘˜è¦"""
        filepath = os.path.join(self.base_path, "compressed_context.json")
        try:
            if os.path.exists(filepath):
                os.remove(filepath)
            return True
        except Exception as e:
            logger.error(f"åˆ é™¤å‹ç¼©æ‘˜è¦å¤±è´¥: {e}")
            return False
    
    # ============================================================
    # æ¨¡æ¿æ¦‚è¦å­˜å‚¨æ–¹æ³•ï¼ˆå¤šç§æ¦‚è¦ç±»å‹ï¼‰
    # ============================================================
    
    async def load_template_overview(self, template_key: str) -> Optional[Dict]:
        """
        åŠ è½½æŒ‡å®šæ¨¡æ¿çš„æ¦‚è¦
        
        Args:
            template_key: æ¨¡æ¿é”®åï¼ˆå¦‚ story_summary, recap, no_spoiler ç­‰ï¼‰
        
        Returns:
            Dict: æ¨¡æ¿æ¦‚è¦æ•°æ®
        """
        filename = f"overview_{template_key}.json"
        return self._load_json(filename, None)
    
    async def save_template_overview(self, template_key: str, data: Dict) -> bool:
        """
        ä¿å­˜æŒ‡å®šæ¨¡æ¿çš„æ¦‚è¦
        
        Args:
            template_key: æ¨¡æ¿é”®å
            data: æ¦‚è¦æ•°æ®
        """
        filename = f"overview_{template_key}.json"
        data["saved_at"] = datetime.now().isoformat()
        data["template_key"] = template_key
        return self._save_json(filename, data)
    
    async def delete_template_overview(self, template_key: str) -> bool:
        """åˆ é™¤æŒ‡å®šæ¨¡æ¿çš„æ¦‚è¦ç¼“å­˜"""
        filepath = os.path.join(self.base_path, f"overview_{template_key}.json")
        try:
            if os.path.exists(filepath):
                os.remove(filepath)
            return True
        except Exception as e:
            logger.error(f"åˆ é™¤æ¨¡æ¿æ¦‚è¦å¤±è´¥: {e}")
            return False
    
    async def list_template_overviews(self) -> List[Dict]:
        """åˆ—å‡ºæ‰€æœ‰å·²ç”Ÿæˆçš„æ¨¡æ¿æ¦‚è¦"""
        overviews = []
        for filename in os.listdir(self.base_path):
            if filename.startswith("overview_") and filename.endswith(".json"):
                template_key = filename[9:-5]  # å»æ‰ "overview_" å’Œ ".json"
                data = await self.load_template_overview(template_key)
                if data:
                    overviews.append({
                        "template_key": template_key,
                        "template_name": data.get("template_name", template_key),
                        "template_icon": data.get("template_icon", "ğŸ“„"),
                        "generated_at": data.get("generated_at"),
                        "has_content": bool(data.get("content"))
                    })
        return overviews
    
    async def clear_all_template_overviews(self) -> bool:
        """æ¸…é™¤æ‰€æœ‰æ¨¡æ¿æ¦‚è¦ç¼“å­˜"""
        try:
            for filename in os.listdir(self.base_path):
                if filename.startswith("overview_") and filename.endswith(".json"):
                    filepath = os.path.join(self.base_path, filename)
                    os.remove(filepath)
            return True
        except Exception as e:
            logger.error(f"æ¸…é™¤æ¨¡æ¿æ¦‚è¦å¤±è´¥: {e}")
            return False
    
    # ============================================================
    # æ‰¹é‡åˆ†æå­˜å‚¨æ–¹æ³•
    # ============================================================
    
    async def load_batch_analysis(self, start_page: int, end_page: int) -> Optional[Dict]:
        """åŠ è½½æ‰¹é‡åˆ†æç»“æœ"""
        filename = f"batches/batch_{start_page:03d}_{end_page:03d}.json"
        return self._load_json(filename, None)
    
    async def save_batch_analysis(self, start_page: int, end_page: int, analysis: Dict) -> bool:
        """ä¿å­˜æ‰¹é‡åˆ†æç»“æœ"""
        filename = f"batches/batch_{start_page:03d}_{end_page:03d}.json"
        analysis["saved_at"] = datetime.now().isoformat()
        analysis["page_range"] = {"start": start_page, "end": end_page}
        return self._save_json(filename, analysis)
    
    async def list_batches(self) -> List[Dict]:
        """åˆ—å‡ºæ‰€æœ‰æ‰¹é‡åˆ†æç»“æœ"""
        batches_dir = os.path.join(self.base_path, "batches")
        if not os.path.exists(batches_dir):
            return []
        
        batches = []
        for filename in os.listdir(batches_dir):
            if filename.startswith("batch_") and filename.endswith(".json"):
                try:
                    parts = filename[6:-5].split("_")
                    start_page = int(parts[0])
                    end_page = int(parts[1])
                    batches.append({
                        "start_page": start_page,
                        "end_page": end_page,
                        "filename": filename
                    })
                except (ValueError, IndexError):
                    pass
        return sorted(batches, key=lambda x: x["start_page"])
    
    async def find_batch_for_page(self, page_num: int) -> Optional[Dict]:
        """æ ¹æ®é¡µç æ‰¾åˆ°å¯¹åº”çš„æ‰¹æ¬¡ï¼ˆç”¨äºçˆ¶å­å—æ£€ç´¢ï¼‰"""
        batches = await self.list_batches()
        for batch in batches:
            if batch["start_page"] <= page_num <= batch["end_page"]:
                return await self.load_batch_analysis(batch["start_page"], batch["end_page"])
        return None
    
    async def delete_batch_analysis(self, start_page: int, end_page: int) -> bool:
        """åˆ é™¤æ‰¹é‡åˆ†æç»“æœ"""
        filepath = os.path.join(self.base_path, f"batches/batch_{start_page:03d}_{end_page:03d}.json")
        try:
            if os.path.exists(filepath):
                os.remove(filepath)
            return True
        except Exception as e:
            logger.error(f"åˆ é™¤æ‰¹é‡åˆ†æå¤±è´¥: {e}")
            return False
    
    # ============================================================
    # å°æ€»ç»“ (Segment) å­˜å‚¨æ–¹æ³•
    # ============================================================
    
    async def load_segment_summary(self, segment_id: str) -> Optional[Dict]:
        """åŠ è½½å°æ€»ç»“"""
        filename = f"segments/{segment_id}.json"
        return self._load_json(filename, None)
    
    async def save_segment_summary(self, segment_id: str, summary: Dict) -> bool:
        """ä¿å­˜å°æ€»ç»“"""
        filename = f"segments/{segment_id}.json"
        summary["saved_at"] = datetime.now().isoformat()
        summary["segment_id"] = segment_id
        return self._save_json(filename, summary)
    
    async def list_segments(self) -> List[Dict]:
        """åˆ—å‡ºæ‰€æœ‰å°æ€»ç»“"""
        segments_dir = os.path.join(self.base_path, "segments")
        if not os.path.exists(segments_dir):
            return []
        
        segments = []
        for filename in os.listdir(segments_dir):
            if filename.endswith(".json"):
                segment_id = filename[:-5]
                data = await self.load_segment_summary(segment_id)
                if data:
                    segments.append({
                        "segment_id": segment_id,
                        "page_range": data.get("page_range", {}),
                        "summary": data.get("summary", "")
                    })
        return sorted(segments, key=lambda x: x.get("page_range", {}).get("start", 0))
    
    async def delete_segment_summary(self, segment_id: str) -> bool:
        """åˆ é™¤å°æ€»ç»“"""
        filepath = os.path.join(self.base_path, f"segments/{segment_id}.json")
        try:
            if os.path.exists(filepath):
                os.remove(filepath)
            return True
        except Exception as e:
            logger.error(f"åˆ é™¤å°æ€»ç»“å¤±è´¥: {e}")
            return False
    
    async def get_segments_for_chapter(self, chapter_id: str, start_page: int, end_page: int) -> List[Dict]:
        """è·å–æŸç« èŠ‚èŒƒå›´å†…çš„æ‰€æœ‰å°æ€»ç»“"""
        all_segments = await self.list_segments()
        chapter_segments = []
        for seg in all_segments:
            seg_range = seg.get("page_range", {})
            seg_start = seg_range.get("start", 0)
            seg_end = seg_range.get("end", 0)
            # æ£€æŸ¥å°æ€»ç»“æ˜¯å¦åœ¨ç« èŠ‚èŒƒå›´å†…
            if seg_start >= start_page and seg_end <= end_page:
                full_data = await self.load_segment_summary(seg["segment_id"])
                if full_data:
                    chapter_segments.append(full_data)
        return chapter_segments
    
    async def clear_batches_and_segments(self) -> bool:
        """æ¸…é™¤æ‰€æœ‰æ‰¹é‡åˆ†æå’Œå°æ€»ç»“"""
        import shutil
        try:
            batches_dir = os.path.join(self.base_path, "batches")
            segments_dir = os.path.join(self.base_path, "segments")
            if os.path.exists(batches_dir):
                shutil.rmtree(batches_dir)
            if os.path.exists(segments_dir):
                shutil.rmtree(segments_dir)
            self._ensure_directories()
            return True
        except Exception as e:
            logger.error(f"æ¸…é™¤æ‰¹é‡åˆ†æå’Œå°æ€»ç»“å¤±è´¥: {e}")
            return False
    
    async def list_pages(self) -> List[int]:
        """åˆ—å‡ºå·²åˆ†æçš„é¡µé¢"""
        pages_dir = os.path.join(self.base_path, "pages")
        if not os.path.exists(pages_dir):
            return []
        
        pages = []
        for filename in os.listdir(pages_dir):
            if filename.startswith("page_") and filename.endswith(".json"):
                try:
                    page_num = int(filename[5:8])
                    pages.append(page_num)
                except ValueError:
                    pass
        return sorted(pages)
    
    async def list_chapters(self) -> List[Dict]:
        """åˆ—å‡ºå·²åˆ†æçš„ç« èŠ‚"""
        chapters_dir = os.path.join(self.base_path, "chapters")
        if not os.path.exists(chapters_dir):
            return []
        
        chapters = []
        for filename in os.listdir(chapters_dir):
            if filename.endswith(".json"):
                chapter_id = filename[:-5]
                analysis = await self.load_chapter_analysis(chapter_id)
                if analysis:
                    chapters.append({
                        "id": chapter_id,
                        "title": analysis.get("title", chapter_id)
                    })
        return chapters
    
    async def clear_all(self) -> bool:
        """æ¸…é™¤æ‰€æœ‰åˆ†æç»“æœ"""
        import shutil
        try:
            if os.path.exists(self.base_path):
                shutil.rmtree(self.base_path)
            self._ensure_directories()
            return True
        except Exception as e:
            logger.error(f"æ¸…é™¤åˆ†æç»“æœå¤±è´¥: {e}")
            return False
    
    async def export_all(self) -> Dict:
        """å¯¼å‡ºæ‰€æœ‰åˆ†ææ•°æ®"""
        # åŠ è½½æ‰¹é‡åˆ†æ
        batches = []
        for batch_info in await self.list_batches():
            batch_data = await self.load_batch_analysis(
                batch_info["start_page"], 
                batch_info["end_page"]
            )
            if batch_data:
                batches.append(batch_data)
        
        # åŠ è½½å°æ€»ç»“
        segments = []
        for seg_info in await self.list_segments():
            seg_data = await self.load_segment_summary(seg_info["segment_id"])
            if seg_data:
                segments.append(seg_data)
        
        return {
            "book_id": self.book_id,
            "metadata": await self.load_metadata(),
            "overview": await self.load_overview(),
            "timeline": await self.load_timeline(),
            "pages": [await self.load_page_analysis(p) for p in await self.list_pages()],
            "batches": batches,
            "segments": segments,
            "exported_at": datetime.now().isoformat()
        }
    
    # ============================================================
    # ç»­å†™åŠŸèƒ½æ•°æ®å­˜å‚¨
    # ============================================================
    
    async def load_continuation_script(self) -> Optional[Dict]:
        """åŠ è½½ç»­å†™è„šæœ¬"""
        return self._load_json("continuation/script.json", None)
    
    async def save_continuation_script(self, script: Dict) -> bool:
        """ä¿å­˜ç»­å†™è„šæœ¬"""
        script["saved_at"] = datetime.now().isoformat()
        return self._save_json("continuation/script.json", script)
    
    async def load_continuation_pages(self) -> Optional[List]:
        """åŠ è½½ç»­å†™é¡µé¢è¯¦æƒ…åˆ—è¡¨"""
        return self._load_json("continuation/pages.json", None)
    
    async def save_continuation_pages(self, pages: List) -> bool:
        """ä¿å­˜ç»­å†™é¡µé¢è¯¦æƒ…åˆ—è¡¨"""
        data = {
            "pages": pages,
            "saved_at": datetime.now().isoformat()
        }
        return self._save_json("continuation/pages.json", data)
    
    async def load_continuation_config(self) -> Optional[Dict]:
        """åŠ è½½ç»­å†™é…ç½®"""
        return self._load_json("continuation/config.json", None)
    
    async def save_continuation_config(self, config: Dict) -> bool:
        """ä¿å­˜ç»­å†™é…ç½®"""
        config["saved_at"] = datetime.now().isoformat()
        return self._save_json("continuation/config.json", config)
    
    async def load_continuation_all(self) -> Dict:
        """åŠ è½½æ‰€æœ‰ç»­å†™æ•°æ®"""
        script = await self.load_continuation_script()
        pages_data = await self.load_continuation_pages()
        config = await self.load_continuation_config()
        
        return {
            "script": script,
            "pages": pages_data.get("pages", []) if pages_data else [],
            "config": config,
            "has_data": script is not None or (pages_data is not None and len(pages_data.get("pages", [])) > 0)
        }
    
    async def clear_continuation_data(self) -> bool:
        """æ¸…é™¤æ‰€æœ‰ç»­å†™æ•°æ®"""
        import shutil
        continuation_path = os.path.join(self.base_path, "continuation")
        try:
            if os.path.exists(continuation_path):
                # åªåˆ é™¤è„šæœ¬å’Œé¡µé¢æ•°æ®ï¼Œä¿ç•™ç”Ÿæˆçš„å›¾ç‰‡
                for filename in ["script.json", "pages.json", "config.json"]:
                    filepath = os.path.join(continuation_path, filename)
                    if os.path.exists(filepath):
                        os.remove(filepath)
            return True
        except Exception as e:
            logger.error(f"æ¸…é™¤ç»­å†™æ•°æ®å¤±è´¥: {e}")
            return False
